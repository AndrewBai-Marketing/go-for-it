\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{float}

\definecolor{newcolor}{RGB}{0,100,0}
\newcommand{\new}{\textcolor{newcolor}{\textbf{NEW}}}

\title{Update: Learning by Decision Margin}
\author{Andrew Bai}
\date{\today}

\begin{document}

\maketitle

\section*{The Core Paradox (Visual Summary)}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{outputs/figures/fourth_down_trends.png}
\caption{The central puzzle: Fourth-down aggression increased dramatically (+8pp over the period), but decision \textit{quality} stayed flat ($-0.05$ pp/year). Coaches changed behavior but not accuracy.}
\end{figure}

\section*{Overview}

This update addresses your suggestion to decompose learning by decision margin. The key question: \textit{where} did coaches learn (or fail to learn)?

\section*{Main Finding}

\textbf{Coaches got worse on close calls, stayed flat on easy decisions.}

\begin{center}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Margin} & \textbf{N Plays} & \textbf{Share} & \textbf{Optimal \%} & \textbf{Trend (pp/yr)} \\
\midrule
Close (0--2pp) & 38,272 & 53.3\% & 69.2\% & $-0.17$ \\
Moderate (2--5pp) & 22,256 & 31.0\% & 91.9\% & $-0.20$ \\
Clear (5--10pp) & 10,964 & 15.3\% & 98.5\% & $-0.01$ \\
Obvious (10+pp) & 216 & 0.3\% & 98.6\% & $-0.06$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Interpretation:} 53\% of fourth downs are close calls ($<$2pp margin). Coaches are getting \textit{worse} on these ($-0.17$ pp/year). On obvious decisions, they were already near-perfect and stayed that way.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{outputs/figures/learning_by_margin.png}
\caption{Left: Decision quality by margin size. Most decisions (53\%) are close calls with only 69\% optimality. Right: Learning trends show coaches getting \textit{worse} on close calls and moderate decisions.}
\end{figure}

\section*{The Short Yardage Paradox}

The most striking pattern is in short yardage (4th \& 1--2):

\begin{center}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Metric} & \textbf{2006--2012} & \textbf{2019--2024} & \textbf{Change} \\
\midrule
Coach go-for-it rate & 32.5\% & 54.6\% & \textbf{+22.1 pp} \\
Model go-for-it rate & 34.8\% & 36.6\% & +1.8 pp \\
Optimal decision rate & 60.9\% & 56.5\% & $-4.4$ pp \\
\midrule
Under-aggressive errors & 20.5\% & 12.5\% & $-8.0$ pp \\
Over-aggressive errors & 18.2\% & 30.6\% & \textbf{+12.4 pp} \\
\bottomrule
\end{tabular}
\end{center}

\textbf{The paradox:} Coaches increased their go-for-it rate by 22pp, but the model only says they should go for it 2pp more often. Result: coaches \textit{overcorrected}. Over-aggressive errors nearly doubled.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{outputs/figures/short_yardage_paradox.png}
\caption{The short yardage overcorrection. Left: Coaches increased aggression by 22pp, but the model says only +2pp was warranted. Right: Under-aggressive errors decreased, but over-aggressive errors more than doubled.}
\end{figure}

\subsection*{Compliance by Optimal Action}

\begin{itemize}[nosep]
    \item When model says GO: compliance improved 41\% $\to$ 66\% \hfill \textbf{+1.73 pp/yr}
    \item When model says PUNT: compliance dropped 85\% $\to$ 66\% \hfill $-1.35$ pp/yr
    \item When model says FG: compliance dropped 47\% $\to$ 33\% \hfill $-1.10$ pp/yr
\end{itemize}

\textbf{Coaches learned ``go for it more'' but unlearned ``but not always.''}

\section*{Learning by Game Situation}

\begin{center}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Situation} & \textbf{N Plays} & \textbf{Optimal \%} & \textbf{Trend} \\
\midrule
End game ($<$5 min) & 8,641 & 60.0\% & $+0.16$ \\
Early game ($>$30 min) & 35,466 & 86.0\% & $-0.22$ \\
\midrule
Red zone & 11,943 & 69.3\% & $+0.25$ \\
Midfield & 17,361 & 83.0\% & $-0.37$ \\
\midrule
Short yardage (1--2) & 13,641 & 60.1\% & $-0.33$ \\
Long yardage (6--10) & 23,867 & 88.2\% & $+0.00$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Pattern:} Coaches improve in high-salience situations (end game, red zone) but decline in routine situations (early game, midfield).

\section*{Theoretical Interpretation}

Coaches appear to learn best when:
\begin{enumerate}[nosep]
    \item Feedback is immediate and clear (outcome directly observable)
    \item Stakes are salient (late game, red zone)
    \item Decision structure is simple (two options, not three)
\end{enumerate}

Coaches struggle when:
\begin{enumerate}[nosep]
    \item Feedback is delayed or noisy (punt outcomes are diffuse)
    \item Situations are routine (early game, low scrutiny)
    \item Tradeoffs are complex (midfield where go/punt/FG all viable)
\end{enumerate}

This connects to organizational learning literature: simple heuristics (``go for it more'') propagate through organizations, but conditional rules (``go for it when X but not when Y'') do not.

\section*{Contrast with Two-Point Conversions}

Two-point decisions show a similar pattern to fourth downs when analyzed with the full hierarchical model and expanding window methodology.

\textbf{Methodology:} For each year, we train hierarchical models on all \textit{prior} years in that era only, then evaluate that year's decisions. This mirrors the fourth-down analysis exactly:
\begin{itemize}[nosep]
    \item Full hierarchical 2pt model with offensive \textit{and} defensive team effects
    \item Hierarchical PAT model with kicker-specific effects
    \item Same Bayesian win probability model as fourth-down analysis
    \item Expanding window: 2017 trained on 2015-2016 data, 2018 on 2015-2017, etc.
\end{itemize}

\subsection*{Two-Point Rule Change Analysis (2015)}

The 2015 rule change moved the PAT from the 2-yard line to the 15-yard line, making PATs harder ($\sim$94\% vs $\sim$99\%). This creates a natural experiment: did coaches learn the new decision environment?

\textbf{Defensibly Optimal Metric:} Given the inherent uncertainty in win probability estimates, we define a decision as ``defensibly optimal'' if either (1) it matches the model's recommendation, or (2) the win probability margin between options is below 0.5\%. This threshold reflects the practical limits of model precision---decisions within this margin are genuinely ``too close to call.''

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{outputs/figures/two_point_defensible_learning.png}
\caption{Two-point conversion learning curve around the 2015 rule change. Pre-rule (2013--2014), coaches were $\sim$98\% defensibly optimal. The rule change caused an immediate drop to 85\% in 2015. Coaches then recovered, reaching 99\% by 2024 (+2.0 pp/year, $p < 0.001$).}
\end{figure}

\textbf{Key findings:}
\begin{itemize}[nosep]
    \item Pre-rule (2013--2014): $\sim$98\% defensibly optimal (when PAT was $\sim$99\%)
    \item 2015 (rule change): Immediate drop to 85\%
    \item Recovery: 85\% (2015) $\to$ 99\% (2024), trend $+2.0$ pp/year
    \item By 2024, coaches make defensible decisions in virtually all two-point situations
\end{itemize}

\textbf{Interpretation:} Unlike fourth-down decisions where coaches show flat or declining optimality, two-point decisions show clear learning. The simpler decision structure (two options vs three) and clearer feedback (immediate score impact) may explain why coaches learned effectively here.

\subsection*{The Down 8 vs Down 9 Paradox}

A striking behavioral anomaly in two-point decisions:

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{outputs/figures/down_8_vs_9_paradox.png}
\caption{The Down 8 vs Down 9 paradox. When down 8, going for 2 ties immediately---coaches do this 79\% of the time. When down 9, going for 2 means a field goal can tie later---coaches do this 1\% of the time. But Down 9 has a \textit{higher} optimal 2pt rate (91\% vs 85\%)!}
\end{figure}

\textbf{Behavioral interpretation:}
\begin{itemize}[nosep]
    \item \textbf{Present bias:} Immediate payoff (``tie NOW'') dominates deferred payoff (``FG ties LATER'')
    \item \textbf{Salience:} ``Go for 2 to tie'' is a known heuristic; ``go for 2 so FG ties'' requires calculation
    \item \textbf{Magnitude:} In 107 situations where the model said ``go for 2'' when down 9, coaches kicked the PAT in all but one
\end{itemize}

This is not a close call---it's a systematic blind spot.

\section*{High-Stakes Analysis: Playoffs vs Regular Season}

Do coaches make better decisions under higher stakes? We analyzed both fourth-down and two-point decisions in playoff games versus regular season games.

\begin{center}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Decision Type} & \textbf{Regular Season} & \textbf{Playoffs} & \textbf{Difference} \\
\midrule
Two-point (2016--2024) & 48.5\% & 52.0\% & \textbf{+3.5 pp} \\
Fourth down (2006--2024) & 80.8\% & $\sim$81\% & $\sim$+0.2 pp \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Key finding:} Coaches make \textit{slightly better} decisions in playoffs, particularly for two-point conversions (+3.5 pp). This is consistent with the pattern from game situations: higher stakes lead to better decision-making.

However, the improvement is modest. Even in the highest-stakes games (playoffs), coaches still make suboptimal decisions roughly half the time for two-point conversions and $\sim$20\% of the time for fourth downs.

\section*{What This Adds to the Paper}

\begin{enumerate}
    \item \textbf{Explains} why coaches haven't improved despite analytics revolution
    \item \textbf{Identifies} specific failure modes: overcorrection on short yardage, decline on close calls
    \item \textbf{Predicts} where intervention would help most: close-call situations
    \item \textbf{Connects} to organizational learning theory: simple heuristics spread, conditional rules don't
\end{enumerate}

\section*{Next Steps}

Possible extensions:
\begin{itemize}[nosep]
    \item Team-level heterogeneity in learning (do ``analytics teams'' improve more?)
    \item Coach-level analysis (does experience predict learning?)
    \item Causal mechanisms (what drives overcorrection?)
\end{itemize}

\end{document}
